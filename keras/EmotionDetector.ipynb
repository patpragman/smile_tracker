{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OJj0OY5dtO9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# My Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17013 images belonging to 3 classes.\n",
      "Found 4251 images belonging to 3 classes.\n",
      "Number of training samples in each class in the training set: {'happy': 7192, 'neutral': 4959, 'sad': 4862}\n",
      "Number of test samples in each class in the testing set: {'happy': 1797, 'neutral': 1239, 'sad': 1215}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, RandomFlip, RandomRotation, RandomZoom, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import binary_accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "seed = 415\n",
    "batch_size = 8\n",
    "image_path = \"./images\"\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             validation_split=0.2,\n",
    "                              zoom_range = 0.1, # Randomly zoom image\n",
    "                              width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                              height_shift_range=0.1,\n",
    "                             rotation_range=30\n",
    "                             )\n",
    "\n",
    "\n",
    "# I changed the imagery to grayscale to speed up the training process\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    image_path,\n",
    "    target_size=(227, 227),  # resize for alexnet\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    color_mode=\"grayscale\",\n",
    "    )\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    image_path,\n",
    "    target_size=(227, 227),  # resize for alexnet\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    color_mode=\"grayscale\",\n",
    "    )\n",
    "\n",
    "train_class_counts = train_generator.classes\n",
    "test_class_counts = test_generator.classes\n",
    "\n",
    "train_class_count = dict(zip(train_generator.class_indices.keys(), np.zeros(len(train_generator.class_indices), dtype=int)))\n",
    "test_class_count = dict(zip(test_generator.class_indices.keys(), np.zeros(len(test_generator.class_indices), dtype=int)))\n",
    "\n",
    "for label in train_class_counts:\n",
    "    train_class_count[list(train_generator.class_indices.keys())[int(label)]] += 1\n",
    "\n",
    "for label in test_class_counts:\n",
    "    test_class_count[list(test_generator.class_indices.keys())[int(label)]] += 1\n",
    "\n",
    "print('Number of training samples in each class in the training set:', train_class_count)\n",
    "print('Number of test samples in each class in the testing set:', test_class_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yUhx8OZQIMjE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "85d0c29c-e84b-4b80-a6ff-ded790b0d6d2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 225, 225, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 225, 225, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 110, 110, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 110, 110, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 55, 55, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 53, 53, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 53, 53, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               22151424  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,278,275\n",
      "Trainable params: 22,277,827\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 23:25:46.822331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-13 23:25:46.822345: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-13 23:25:46.822358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pop-os): /proc/driver/nvidia/version does not exist\n",
      "2023-04-13 23:25:46.822529: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor=\"val_categorical_accuracy\", \n",
    "                  patience=250,\n",
    "                  restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_categorical_accuracy\", \n",
    "                      factor=0.50, patience=150, \n",
    "                      verbose=1,\n",
    "                      min_delta=0.0001),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.01)\n",
    "activation = \"relu\"\n",
    "\n",
    "# build the model - I resized the images to use AlexNet\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation=activation, input_shape=(227,227,1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation=activation),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation=activation),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation=activation),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation=activation),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['categorical_accuracy']\n",
    "              )\n",
    "\n",
    "model.build(input_shape=(None, 227, 227, 1))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=500, \n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=my_callbacks)\n",
    "\n",
    "model.save(\"alex_net_emotions_local_1.h5\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKTsphyZMRZo",
    "outputId": "9c380df9-bc0b-4fa0-f43f-15d991328e8f",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2127/2127 [==============================] - 455s 213ms/step - loss: 7.0699 - categorical_accuracy: 0.3907 - val_loss: 1.2501 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "2127/2127 [==============================] - 441s 207ms/step - loss: 1.1251 - categorical_accuracy: 0.4194 - val_loss: 1.0814 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "2127/2127 [==============================] - 433s 204ms/step - loss: 1.1100 - categorical_accuracy: 0.4225 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "2127/2127 [==============================] - 433s 204ms/step - loss: 1.0939 - categorical_accuracy: 0.4224 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "2127/2127 [==============================] - 431s 203ms/step - loss: 1.1045 - categorical_accuracy: 0.4226 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "2127/2127 [==============================] - 431s 202ms/step - loss: 1.0857 - categorical_accuracy: 0.4230 - val_loss: 1.0815 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "2127/2127 [==============================] - 430s 202ms/step - loss: 1.0901 - categorical_accuracy: 0.4227 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "2127/2127 [==============================] - 432s 203ms/step - loss: 1.0820 - categorical_accuracy: 0.4228 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "2127/2127 [==============================] - 434s 204ms/step - loss: 1.1074 - categorical_accuracy: 0.4227 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "2127/2127 [==============================] - 435s 205ms/step - loss: 1.0824 - categorical_accuracy: 0.4227 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "2127/2127 [==============================] - 437s 205ms/step - loss: 1.0845 - categorical_accuracy: 0.4227 - val_loss: 1.0814 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "2127/2127 [==============================] - 438s 206ms/step - loss: 1.1056 - categorical_accuracy: 0.4226 - val_loss: 1.0813 - val_categorical_accuracy: 0.4227 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1174/2127 [===============>..............] - ETA: 3:05 - loss: 1.0899 - categorical_accuracy: 0.4230"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um-xf08F56bm",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "y_actual = test_generator.classes\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_actual, y_pred)\n",
    "print(confusion_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print(classification_report(test_generator.classes, y_pred))\n",
    "\n",
    "plt.imshow(confusion_mtx, cmap='binary', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(3)\n",
    "plt.xticks(tick_marks, ['Happy', 'Neutral', 'Sad'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Happy', 'Neutral', 'Sad'])\n",
    "\n",
    "thresh = confusion_mtx.max() / 2.\n",
    "for i in range(confusion_mtx.shape[0]):\n",
    "    for j in range(confusion_mtx.shape[1]):\n",
    "        plt.text(j, i, format(confusion_mtx[i, j]), ha=\"center\", va=\"center\", color=\"white\" if confusion_mtx[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('CNN Model')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}